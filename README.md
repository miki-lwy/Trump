# Trump
I've created 3 mini-projects to analyse Trump's tweets
1) Text analysis of Trump's tweets
  - to understand the tweeting habits/ pattern/ characteristics on different devices
  - learn to create a wordcloud
  - use natural language processing technique to identify the sentiment of words used on different devices
2) Strategy for Trump's US election 2016
  - to identify the change of words used before and after US election and understand how Trump changed his strategy to defend his position
3) who_was_tweeting_for_Trump.ipynb
  - learn to handle imbalance dataset
  - leverage the first mini-project - Text analysis of Trump's tweets to predict which tweets were written by Trump himself


# Installation
```
Install jupyter notebook (please see https://jupyter.org/install for the details)
```

# Required libraries
```
pip install pandas
pip install matplotlib
pip install seaborn
pip install nrclex
pip install nltk
pip install sklearn
pip install wordcloud

```
# Dataset
You can download it in the following website:
https://www.thetrumparchive.com/

# Run
```
git clone https://github.com/miki-lwy/Trump
cd Trump
jupyter notebook
```

# Reference
[code in R] http://varianceexplained.org/r/trump-tweets/
[code in R] http://varianceexplained.org/r/trump-followup/
